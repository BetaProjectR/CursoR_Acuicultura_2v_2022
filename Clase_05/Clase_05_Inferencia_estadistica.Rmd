---
title: "Clase 05 - Inferencia estadística"
subtitle: 'Curso Introducción al Análisis de datos con R para la Acuicultura.'
author: Dr. José Gallardo Matus
institute: Pontificia Universidad Católica de Valparaíso 
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  beamer_presentation:
    theme: "Malmoe"
    colortheme: "seahorse"
    fonttheme: "professionalfonts"
    includes:
      in_header: mystyle.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(UsingR)
library(dplyr)
```

# PLAN DE LA CLASE
**1.- Introducción**
    
- ¿Qué es la inferencia estadística?.   
- ¿Cómo someter a prueba una hipótesis?
- Pruebas paramétricas
- Interpretar resultados de análisis de datos con R.

**2.- Práctica con R y Rstudio cloud**

- Someter a prueba diferentes hipótesis estadísticas.
- Realizar gráficas avanzadas con ggplot2. 

# ¿QUÉ ES LA INFERENCIA ESTADÍSTICA?

**Inferencia estadística :** Son procedimientos que permiten obtener o extraer conclusiones sobre los parámetros de una población a partir de una muestra de datos tomada de ella.


```{r, echo=FALSE, out.width = '100%' }
knitr::include_graphics("Inferencia.png")
```

**¿Qué inferencia puede hacer de los datos de esta población?**  
**¿Qué ocurre si la muestra no es aleatoria?**

# INFERENCIA ESTADÍSTICA

**¿Par qué es importante la inferencia estadística?**  

- **Es más económico que hacer un Censo.**  
  ¿Cuántas especies hay en una bahía, en una laguna, en un bosque? 
  
- **Bajo ciertos supuestos permite hacer afirmaciones.**  
  Con aditivo A los peces crecen más que con aditivo B.  
  
- **Bajo ciertos supuestos permite hacer predicciones.**  
  Peces con genotipo GG maduran más que peces con genotipo AA. 
  
# INFERENCIA ESTADÍSTICA: MÉTODOS 

Los métodos de inferencia estadística que revisaremos en este curso son:\
&nbsp;  

1. **Estimación de parámetros a partir de una muestra.**\
&nbsp;  

2. **Pruebas de contraste de hipótesis.**\
&nbsp;  

3. **Modelamiento predictivo.**\
&nbsp;  
  
# CONCEPTOS IMPORTANTES

- **Parámetro**  
Constante que caracteriza a todos los elementos de un conjunto de datos de una población. Se representan con letras griegas.

Promedio de una población (mu) = $\mu$.
 
- **Estadístico**  
Una función de una muestra aleatoria o subconjunto de datos de una población.

Promedio de una muestra ($\bar{X}$) = $\sum$ $\frac{X_i}{n}$

# ESTIMACIÓN DE PARÁMETROS

**Objetivo**
Hacer generalizaciones de una población a partir de una muestra.

**Tipos de estimación**    

- **Estimación puntual:** Consiste en asumir que el parámetro tiene el mismo valor que el estadístico en la muestra.  
Ej. media de cortisol en plasma es de 15  $\mu gramos / decilitro$ (N=30).

- **Estimación por intervalos:** Se asigna al parámetro un conjunto de posibles valores que están comprendidos en un intervalo asociado a una cierta probabilidad de ocurrencia. 
Ej. Intervalo de confianza: del 95% nuestro parámetro estará entre 10 y 20 $\mu gramos / decilitro$, 95 de 100 veces.

# ERROR EN LA ESTIMACIÓN DE PARÁMETRO.

**¿Puedo estimar erróneamente un parámetro?**  
Por supuesto, los errores se producen por violar algunas premisas.

- **Las muestras deben tomarse de forma aleatoria.**  
  Si los peces grandes son más fáciles de capturar que peces pequeños, la biomasa de una laguna será menor que la predicha.

- **Ley de los grandes números.**  
  Compare experimento de 3 muestras v/s 300 muestras.     
  
- **Otros**  
  Errores, Equipos descalibrados, Fraude.     
  
# PRUEBAS DE HIPÓTESIS

**Objetivo**  
Realizar una afirmación acerca del valor de un parámetro, usualmente contrastando con alguna hipótesis.

**Hipótesis estadísticas**  
*Hipótesis nula* (H~0~) es una afirmación, usualmente de igualdad. 

*Hipótesis alternativa* (H~A~) es una afirmación que se deduce de la observación previa o de los antecedentes de literatura y que el investigador cree que es verdadera.

**Ejemplo**  
**H~0~**: El nivel medio de cortisol es = 15 microgramos por decilitro.  
**H~A~**: El nivel medio de cortisol es > 15 microgramos por decilitro.  

# ETAPAS DE UNA PRUEBA DE HIPÓTESIS

Para cualquier prueba de hipótesis necesitas lo siguiente:

- Los **_Datos_** (1).

- Una **_hipótesis nula_** (2).
 
- Una **_prueba estadística_** (3) que se aplicará.

- El **_nivel de significancia_** (4) para rechazar la hipótesis.

- La **_distribución_** (5) de la **prueba estadística** respecto de la cual se evaluará la *hipótesis nula* con el estadístico que estimas de tus *datos*.


# ERROR EN LAS PRUEBAS DE HIPÓTESIS

Por supuesto, siempre es posible llegar a una conclusión incorrecta.

**Tipos de errores**  
Tipo I ($\alpha$) y tipo II ($\beta$), ambos están inversamente relacionados.

 **Decisión** |  **H~0~ es cierta** | **H~0~ es falsa** | 
---- | ---- | ---- |
*Aceptamos H~0~* | Decisión correcta | Error tipo II |
*Rechazamos H~0~* | Error tipo I | Decisión correcta |  

# ¿CUÁNDO RECHAZAR **H~0~**?

**Regla de decisión**  
Rechazo **H~0~** cuando la evidencia observada es poco probable que ocurra bajo el supuesto de que la hipótesis sea verdadera. 

Generalmente $\alpha$ = 0,05 o 0,01.

Es decir, rechazamos cuando el valor del estadístico está en el 5% inferior de la función de distribución muestral.

**Corrección de Bonferroni para comparaciones múltiples**

Pero a veces $\alpha$ = $10^{-8}$  

Ejemplo: Evaluó 50.000 genotipos diferentes para investigar cual está asociado a ser resistente al Coronavirus.
Solo por azar 2.500 estarán asociados con P < 0,05

# PRUEBA DE HIPÓTESIS: UNA COLA O DOS COLAS

```{r, echo=FALSE, out.width = '100%',fig.align='center'}
knitr::include_graphics("region_rechazo.png")
```

# TIPOS DE PRUEBAS ESTADÍSTICAS

Según la forma de la distribución de la variable aleatoria.

1. **Métodos paramétricos**
  * Las pruebas de hipótesis usualmente asumen una distribución normal de la variable aleatoria.
  * Útil para la mayoría de las variables cuantitativas continuas.

2. **Métodos NO paramétricos**
  * Las pruebas de hipótesis no asumen una distribución normal de la variable aleatoria.
  * Útil para todas las variables, incluyendo cuantitativas discretas y cualitativas.


# CORRELACIÓN ENTRE VARIABLES

```{r, echo=FALSE, out.width = '100%',fig.align='center'}
knitr::include_graphics("Correlation.png")
```

# ESTUDIO DE CASO: TAMAÑO PADRES - HIJOS

```{r,message=FALSE, echo=FALSE, out.width = '100%',fig.align='center'}
My_Theme = theme(
  axis.title.x = element_text(size = 18),
  axis.text.x = element_text(size = 18),
  axis.title.y = element_text(size = 18),
  axis.text.y = element_text(size = 18))

ggplot(data = father.son) +
  geom_point(aes(x = fheight, y = sheight),
                     col = 'darkblue',
                     size = 2,
                     alpha = 1/2) + 
  geom_smooth(aes(x = fheight, y = sheight), method = 'lm')+
  labs( x="Tamaño padres", y="Tamaño hijos") + My_Theme

```


# HIPÓTESIS PRUEBA DE CORRELACIÓN
**Hipótesis**  
$H_0$ : $\rho$ = 0 ausencia de correlación.      
$H_1$ : $\rho$ $\neq$ 0 existencia de correlación.    

**Supuestos:**  
	1) Las variables X e Y son continuas y su relación en lineal.     
	2) La distribución conjunta de (X,Y) es una distribución Bivariable normal.    
	


#  PRUEBA DE CORRELACIÓN DE PEARSON

```{r, echo=TRUE}
cor.test(father.son$fheight, father.son$sheight,
         alternative = c("two.sided"))

```

# DISTRIBUCIÓN T STUDENT

Origen: [William Sealy Gosset](https://es.wikipedia.org/wiki/William_Sealy_Gosset), estadístico de la cervecería Guinness.

```{r}
#create density plots
curve(dt(x, df=6), from=-5, to=5, col='blue', ylab = 'Density', xlab = "t-values", cex.lab=1.5, cex.axis=1.5) 
curve(dt(x, df=10), from=-5, to=5, col='red', add=TRUE)
curve(dt(x, df=30), from=-5, to=5, col='green', add=TRUE)

#add legend
legend(-5, .3, legend=c("df=6", "df=10", "df=30"),
       col=c("blue", "red", "green"), lty=1.5, cex=1.5)
```

# PRUEBA DE HIPÓTESIS

- gl correlación = Nº datos - 2 = 1078 - 2
- Región de no rechazo= t-student (gl=1076) =
`r round(-qt(0.975, df=1076),2)` - `r round(qt(0.975, df=1076),2)`


```{r, out.width = '80%',fig.align='center'}
curve(dt(x, df=1076), from=-5, to=5, col='blue', ylab = 'Density', xlab = "t-values", lwd=3, cex.lab=1.5, cex.axis=1.5) 
abline(v=qt(0.975, df=1076),lty= 3, col = 'blue')
abline(v= - qt(0.975, df=1076),lty= 3, col = 'blue')

text(3.28, 0.135, "t-obs. = 19,006", cex=1.5)
arrows(x0 = 3.28,
       y0 = 0.1,
       x1 = 5.28,
       y1 = 0.04)

text(0, 0.135, "No rechaza", col="blue", cex=1.5)
text(-3.5, 0.35, "Rechaza H0", col="red", cex=1.5)
text(3.5, 0.35, "Rechaza H0", col="red", cex=1.5)

```


# PRUEBA DE COMPARACIÓN DE MEDIAS

```{r , echo=FALSE, out.width = '80%',fig.align='center'}
knitr::include_graphics("t-student.png")
```

# ESTUDIO DE CASO: CORTISOL EN SALMON

```{r, out.width = '90%'}
set.seed(123)

My_Theme = theme(
  axis.title.x = element_text(size = 18),
  axis.text.x = element_text(size = 18),
  axis.title.y = element_text(size = 18),
  axis.text.y = element_text(size = 18))

dat<- data.frame(Tratamiento=rep(c("Stress", "Control"), each=10), Cortisol=c(rnorm(10, 20, 5),rnorm(10, 10, 5)))


ggplot(dat, aes(x=Tratamiento, y=Cortisol, fill=Tratamiento))+
 geom_boxplot()+
  labs( x="Tratamiento", y="Cortisol nanogramos / mililitro") + My_Theme+theme(legend.position='none')

```

[Adaptado de Fast, et al. 2006](https://doi.org/10.1016/j.fsi.2007.10.009.)

# HIPÓTESIS COMPARACIÓN DE MEDIAS
**Hipótesis**  
$H_0$ : $\mu_1$ = $\mu_2$.  
$H_1$ : $\mu_1$ $\neq$ $\mu_2$  

**Supuestos**  
1) Las variables X es continua.  
2) Distribución normal.  

# PRUEBA DE T PARA DOS MUESTRAS INDEPENDIENTES

```{r, echo=TRUE}
t.test(Cortisol ~ Tratamiento, dat, var.equal=TRUE,
       alternative = c("two.sided"))

```

# PRUEBA DE HIPÓTESIS

- gl correlación = Nº datos - 2 = 20 - 2
- Región de no rechazo distribución t-student (gl=18)=
`r round(-qt(0.975, df=18),2)` - `r round(qt(0.975, df=18),2)`

```{r, out.width = '80%',fig.align='center'}
curve(dt(x, df=18), from=-5, to=5, col='blue', ylab = 'Density', xlab = "t-values", lwd=3, cex.lab=1.5, cex.axis=1.5) 
abline(v=qt(0.975, df=18),lty= 2, col = 'blue')
abline(v= - qt(0.975, df=18),lty= 2, col = 'blue')

text(-3.6, 0.15, "t-obs. = -4,18", cex=1.5)
arrows(x0 = -3.28,
       y0 = 0.1,
       x1 = -4.41,
       y1 = 0.004)

text(0, 0.135, "No rechaza", col="blue", cex=1.5)
text(-3.5, 0.35, "Rechaza H0", col="red", cex=1.5)
text(3.5, 0.35, "Rechaza H0", col="red", cex=1.5)

```


# PRÁCTICA ANÁLISIS DE DATOS


```{r, echo=FALSE, out.width = '100%',fig.align='center'}
knitr::include_graphics("testing_hyphotesis.jpeg")
```

# RESUMEN DE LA CLASE

1. **Conceptos básicos de inferencia estadística**  
    * Estadístico y parámetro.\
&nbsp;    
    
2. **Conceptos básicos de pruebas de hipótesis**  
    * Hipótesis nula, alternativa.\
&nbsp;      
    
3. **Distribución de probabilidad**  
    * t-student.  \
&nbsp;    
  
4. **Realizar pruebas de hipótesis**
    * Test de correlación.  
    * Test de comparación de medias para 2 muestras independientes.

4. **Realizar gráficas avanzadas con ggplot2**.    